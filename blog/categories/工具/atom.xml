<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: 工具 | bd17kaka's blog]]></title>
  <link href="http://zhangdian.github.com/blog/categories/工具/atom.xml" rel="self"/>
  <link href="http://zhangdian.github.com/"/>
  <updated>2013-04-01T20:34:29+08:00</updated>
  <id>http://zhangdian.github.com/</id>
  <author>
    <name><![CDATA[bd17kaka]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[RabbitMQ]]></title>
    <link href="http://zhangdian.github.com/blog/2013/03/27/rabbitmq/"/>
    <updated>2013-03-27T17:02:00+08:00</updated>
    <id>http://zhangdian.github.com/blog/2013/03/27/rabbitmq</id>
    <content type="html"><![CDATA[<h3>RabbitMQ</h3>

<p>RabbitMQ是一个消息代理，它接收和转发消息。它有六种模式，下面介绍其中的四种模式。</p>

<!-- more -->


<h4>1. 最简单的模式</h4>

<p><img src="https://dl.dropbox.com/u/99113526/blog.bd17kaka.net/rabbitmq-1.png"></p>

<h5>1.1 角色</h5>

<ul>
<li>生产者(Producing)除了发送消息之外，什么也不做，用“P”表示；</li>
<li>所有消息都存储在Queue里面，所有消息都流经Queue以及我们的应用程序。Queue没有任何限制，它可以存储尽可能多的消息，本质上，它是一个无穷大(infinite)的buffer；</li>
<li>消费者(Consumer)等待接收消息，用“C”表示。</li>
</ul>


<p>这三个角色没必要在一个机器上，实际上也是这样的。</p>

<h5>1.2 生产者</h5>

<p>生产者发送消息的时候，一定要保证Queue的存在，如果它发送消息到一个不存在的Queue，RabbitMQ会丢弃掉这个消息。</p>

<p><code>
channel.queue_declare(queue='hello')
</code></p>

<p>RabbitMQ中，消息实际上不会直接发送到Qeueu上，而是先发送到Exchange上，不指定Exchange的话，会发送到默认的Exchange（“”，空字符串）上。</p>

<p>需要在routing_key参数中指定Queue的名称：</p>

<p>```
channel.basic_publish(exchange='',</p>

<pre><code>                  routing_key='hello',
                  body='Hello World!')print " [x] Sent 'Hello World!'"
</code></pre>

<p>```</p>

<p>退出之前，需要确保清空缓存，并且所有的消息都发送到RabbitMQ：</p>

<p><code>
connection.close()
</code></p>

<h5>1.3 消费者</h5>

<p>首先要连接到服务器，其次，要保证Queue的存在，使用queue_declare创建Queue是幂等的（idempotent，也就是多次创建，只会有一个同一名字的Queue被创建），所以，重新声明一个Queue永远是比较好的。</p>

<p><code>
channel.queue_declare(queue='hello')
</code></p>

<p>RabbitMQ通过注册一个回调函数来接收消息，每次接收到一个消息的时候，都会调用回调函数。其次，需要指定消费者从指定的Queue来接收消息：</p>

<p>```
def callback(ch, method, properties, body):</p>

<pre><code>print " [x] Received %r" % (body,)
</code></pre>

<p>channel.basic_consume(callback,</p>

<pre><code>                  queue='hello',
                  no_ack=True)
</code></pre>

<p>```</p>

<p>为了保证正确的读取消息，要保证Queue的存在，只要我们在生产者端创建了Queue，那么就可以保证这点。</p>

<p>然后，就会进入到一个永远都不会停止的循环，只要有消息都会调用回调函数。</p>

<h4>2. One producer, multi consumer</h4>

<p><img src="https://dl.dropbox.com/u/99113526/blog.bd17kaka.net/rabbitmq-2.png"></p>

<p>这种模型用于在众多的Workers之间分发一些耗时的任务。</p>

<p>这种模型的主要思想是：避免立即执行资源密集型的任务，等待其完成。而是将任务压缩成一个消息，将其发送到queue。Worker在后台获取这些任务，然后执行它们。如果允许多个Worker，那么它们会公平的分享这些消息。</p>

<p>这个模型特别适合：在一个短的HTTP周期内完成一个很复杂任务的应用。</p>

<h5>2.1 Round-robin dispatching(轮询调度)</h5>

<p>这种模型很容易做到平衡工作调度。如果突然多了很多的消息，那么可以添加更多的Worker来解决，很容易扩展。</p>

<p>默认情况下，RabbitMQ会按顺序的，将每个消息分发给下一个consumer，平均来看，每个consumer会获得相同数目的消息。这种分发消息的模式叫做Round-robin。</p>

<h5>2.2 Message ACK</h5>

<p>当一个worker开始一个耗时的task，但是在执行了一部分的时候失败了。对于当前的RabbitMQ的代码，当一个消息被分发到worker之后，它会立即从内存中删掉。在这种情况下，如果一个worker没有正确的执行完一个消息，那么这个消息就丢失了。</p>

<p>当然，我们不希望丢失掉任何的tasks，如果执行该task的worker挂掉了，那么应该将这个task分发给其他的worker去执行。</p>

<p>为了确保一个消息永远都不会丢失，RabbitMQ引入了消息ACK的机制。当worker执行完了一个task之后，就会发送一个消息给RabbitMQ，说明某个消息已经被执行完毕了，RabbitMQ可以将这个消息删除了。</p>

<p>如果worker挂掉了，那么它就不会发送ACK了，RabbitMQ就知道某个消息没有完整的被执行，然后会重新将这个task发送给其他的worker，这就可以保证消息不会丢失。（但是，如果task执行完了，发送了ACK，由于某种原因，ACK没有成功的抵达RabbitMQ，那么这个task会被重新执行一次。）</p>

<p>在RabbitMQ中，没有消息延迟的概念，task只有在到某个worker的连接断掉之后，才会重发。即使一个task执行了很长很长的时候，也是正常的。</p>

<p>默认情况下，ACK是打开的，也是可以设置的。</p>

<p>有一种常见的错误：在worker执行完了之后，没有返回ACK，那么RabbitMQ会不断的重发消息。但是由于消息都没有返回ACK，那么RabbitMQ会不断的吃内存，将消息保存起来。对于这种情况，可以通过使用rabbitmqctl工具来查看messages_unacknowledged字段：</p>

<p><code>
$ sudo rabbitmqctl list_queues name messages_ready messages_unacknowledged
Listing queues ...
hello    0       0
...done.
</code></p>

<h5>2.2.3 Message durability（消息持久）</h5>

<p>上一节讲到如何保证在worker挂掉的时候，不让消息丢失，但是如何保证RabbitMQ挂掉的时候，不丢失消息呢？那么消息就不能只保存在内存了，必须持久化。</p>

<p>为了保证在RabbitMQ挂掉的时候，消息不丢失，需要做两件事情：queue和messages都是持久化的。</p>

<p>首先要保证RabbitMQ不会丢失Queue，指定durable参数：</p>

<p><code>
channel.queue_declare(queue='task_queue', durable=True)
</code></p>

<p>RabbitMQ不允许使用不同的参数来重定义已经存在的Queue，如果这么做，会返回一个error。所以在上面的代码中，如果Queue "hello"已经存在的话，这样是没有用的，必须指定另外一个Queue名称。</p>

<p>指定了 durable=True 之后，即使RabbitMQ重启，Queue也不会丢失了。</p>

<p>其次，我们需要保证将我们的message标记为持久的了，通过指定参数delivery_mode = 2：</p>

<p>```
channel.basic_publish(exchange='',</p>

<pre><code>                  routing_key="task_queue",
                  body=message,
                  properties=pika.BasicProperties(
                     delivery_mode = 2, # make message persistent
                  ))
</code></pre>

<p>```</p>

<p>注意：
即使通过指定参数来保证保存message消息到disk，从而不会丢失，但是总有一个时刻：RabbitMQ刚刚接手了一个消息，但是还没有保存到disk。<strong>也就是，RabbitMQ并不能保存对每个消息执行fsync。这个持久化的保证并不强大，但是总比简单的task queue要好一点。</strong>如果需要更强大的持久化保证，只能wrap它的代码。</p>

<p><code>
fsync：同步内存中所有已修改的文件数据到储存设备。
[详细](http://baike.baidu.com/view/8092902.htm)
</code></p>

<h5>2.2.4 Fair dispatch（公平分发）</h5>

<p>有些时候，上面的轮训分发并不能完全按照我们想象的来工作，比如：有两个worker，所有奇数的消息都是耗时的，偶数的消息都是不耗时的，那么所有耗时的消息都会被分发到worker-1上，所有不耗时的消息都会被分发到worker-2上。但是RabbitMQ什么都不知道，只能这么简单的分发消息，而并没有考虑某个Worker上UnACK的消息的个数。</p>

<p>可以通过如下设置来解决这个问题：</p>

<p><code>
channel.basic_qos(prefetch_count=1)
</code>
这个参数告诉RabbitMQ，不要在同一时刻向同一个worker分发多余一个的消息，也就是说，在接受到之前的task的ACK之前，不要再分发消息给worker。</p>

<p><strong>当心Queue的大小：如果所有的Queue都busy，那么Queue就会不断变长，要么一直盯着，要么增加更多的worker，要么使用一些其他的策略。
</strong></p>

<h5>2.2.5 完整代码</h5>

<p><a href="http://www.rabbitmq.com/tutorials/tutorial-two-python.html">官方网站</a></p>

<h4>3 订阅发布</h4>

<p>在前面的模式中，每个消息只会发送到一个worker。在这里的“订阅发布”模式中，会发送一个消息给多个consumer。</p>

<h5>3.1 Exchanges</h5>

<p>在前面的部分中，只是介绍了从一个单独的Queue来接受消息，这里会介绍RabbitMQ的完整的消息模型。</p>

<p><img src="https://dl.dropbox.com/u/99113526/blog.bd17kaka.net/rabbitmq-2.png"></p>

<p>在RabbitMQ中，producer永远不会直接将消息发送给Queue，实际上Producer甚至并不知道一个消息会被发送到一个Queue上。Producer只是将消息发送到exchange上。exchange一方面接收消息，一方面将消息推送到Queue上。Exchange必须知道如何处理每个接收到的消息：附加到一个Queue上？附加到多个Queue上？还是忽略之。</p>

<p>有很多种可用的exchange：direct, topic, headers and fanout。本节，主要介绍fanout。创建一个fanout类型的exchange：</p>

<p>```
channel.exchange_declare(exchange='logs',</p>

<pre><code>                     type='fanout')
</code></pre>

<p>```</p>

<p>fanout类型的exchange的作用很简单，就是将它接收到得所有消息，分发到每一个它所知道的Queue。</p>

<p>然后就可以将消息发送到“logs”这个exchange：</p>

<p>```
channel.basic_publish(exchange='logs',</p>

<pre><code>                  routing_key='',
                  body=message)
</code></pre>

<p>```</p>

<h5>3.2 临时Queue</h5>

<p>我们有时只关注当前的消息，而并不关注之前的消息，或者希望在consumer断开与RabbitMQ的连接之后，不保存Queue中的消息，那么可以使用临时Queue。要做到这点，需要两点：</p>

<ul>
<li>在server端创建一个使用随机Queue名称的channel；</li>
<li>客户端在声明Queue的时候，加上exclusive=true参数；</li>
</ul>


<p><code>
(客户端)
result = channel.queue_declare(exclusive=True)
</code></p>

<h5>3.3 绑定</h5>

<p>接下来，就需要绑定：</p>

<p>```
(客户端)
channel.queue_bind(exchange='logs',</p>

<pre><code>               queue=result.method.queue)
</code></pre>

<p>```</p>

<h4>4 Routing</h4>

<p>这一节介绍的模型可以只将所有消息的子集发送到某个指定的Queue。比如在日志系统中，可以将error消息和warning消息发送到两个不一样的Queue。</p>

<p>在bing过程中，可以指定一个routing_key参数：</p>

<p>```
channel.queue_bind(exchange=exchange_name,</p>

<pre><code>               queue=queue_name,
               routing_key='black')
</code></pre>

<p>```</p>

<p>routing_key在有的类型的exchange中是被忽视的，比如在前面的fanout模型中，是被忽略的。</p>

<h5>4.1 Direct exchange</h5>

<p><img src="https://dl.dropbox.com/u/99113526/blog.bd17kaka.net/rabbitmq-4.png"></p>

<p>在这个图中可以看到，exchange和两个Queue绑定，第一个Queue和routing_key为orange的消息绑定，第二个Queue和routing_key为black和green的Queue绑定。</p>

<p>消息根据它们的routing_key被分发到不同的Queue。</p>

<p>也可以将一个routing_key绑定到多个Queue，如果绑定到所有的Queue的话，那么这种模型和fanout exchange就是一样的了。</p>

<h5>4.2 producer分发消息</h5>

<p>```
channel.exchange_declare(exchange='direct_logs',</p>

<pre><code>                     type='direct')
</code></pre>

<p>channel.basic_publish(exchange='direct_logs',</p>

<pre><code>                  routing_key=severity,
                  body=message)
</code></pre>

<p>```</p>

<h5>4.3 consumer消费消息</h5>

<p>```
result = channel.queue_declare(exclusive=True)queue_name = result.method.queue</p>

<p>for severity in severities:</p>

<pre><code>channel.queue_bind(exchange='direct_logs',
                   queue=queue_name,
                   routing_key=severity)
</code></pre>

<p>```</p>

<p>continue...</p>
]]></content>
  </entry>
  
</feed>
